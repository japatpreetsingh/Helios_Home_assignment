{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "106c4766",
      "metadata": {
        "id": "106c4766"
      },
      "outputs": [],
      "source": [
        "#import necessary libraries\n",
        "import cv2\n",
        "import torch\n",
        "import time\n",
        "import PIL.Image\n",
        "from torchvision import transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f07e3753",
      "metadata": {
        "id": "f07e3753"
      },
      "outputs": [],
      "source": [
        "def real_time_evaluation(model, transform, device='cpu'):\n",
        "    # Initialize video capture\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    # Set camera resolution to 720p\n",
        "    cap.set(3, 1280)  # Width\n",
        "    cap.set(4, 720)   # Height\n",
        "\n",
        "    # Initialize FPS counter\n",
        "    prev_frame_time = 0\n",
        "    new_frame_time = 0\n",
        "\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Calculate FPS\n",
        "        new_frame_time = time.time()\n",
        "        fps = int(1/(new_frame_time-prev_frame_time))\n",
        "        prev_frame_time = new_frame_time\n",
        "\n",
        "        # Preprocess frame\n",
        "        image = PIL.Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "        image = transform(image)\n",
        "        image = image.unsqueeze(0).to(device)\n",
        "\n",
        "        # Get prediction\n",
        "        with torch.no_grad():\n",
        "            prediction = model(image)\n",
        "            prob = torch.nn.functional.softmax(prediction, dim=1)\n",
        "            score, pred_idx = torch.max(prob, 1)\n",
        "\n",
        "        # Display results on frame\n",
        "        cv2.putText(frame, f'Class: {pred_idx.item()}', (30, 50),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f'Score: {score.item():.2f}', (30, 90),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "        cv2.putText(frame, f'FPS: {fps}', (30, 130),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "        # Display frame in Jupyter notebook\n",
        "        cv2.imshow('Real-time Evaluation', frame)\n",
        "\n",
        "        # Press 'q' to quit\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9e502a1",
      "metadata": {
        "id": "d9e502a1"
      },
      "outputs": [],
      "source": [
        "# Define your transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                        std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TrafficSignNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TrafficSignNet, self).__init__()\n",
        "\n",
        "        # First convolutional block\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=7, padding=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Second convolutional block\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128, 128, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Third convolutional block\n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(512 * 4 * 4, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(2048, 43)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        #x = x.view(x.size(0), -1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "SdRPfhcD0dqj"
      },
      "id": "SdRPfhcD0dqj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TrafficSignNet().to(device)\n",
        "model.load_state_dict(torch.load('C:\\Users\\ARUSHI\\OneDrive\\Desktop\\helios\\traffic_sign_detection.pt'))"
      ],
      "metadata": {
        "id": "ZOQea4AA0qwt"
      },
      "id": "ZOQea4AA0qwt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec65acbc",
      "metadata": {
        "id": "ec65acbc"
      },
      "outputs": [],
      "source": [
        "# Call the function with your model\n",
        "real_time_evaluation(model, transform)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}